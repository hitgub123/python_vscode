[
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "Elasticsearch",
        "importPath": "elasticsearch",
        "description": "elasticsearch",
        "isExtraImport": true,
        "detail": "elasticsearch",
        "documentation": {}
    },
    {
        "label": "Elasticsearch",
        "importPath": "elasticsearch",
        "description": "elasticsearch",
        "isExtraImport": true,
        "detail": "elasticsearch",
        "documentation": {}
    },
    {
        "label": "helpers",
        "importPath": "elasticsearch",
        "description": "elasticsearch",
        "isExtraImport": true,
        "detail": "elasticsearch",
        "documentation": {}
    },
    {
        "label": "Elasticsearch",
        "importPath": "elasticsearch",
        "description": "elasticsearch",
        "isExtraImport": true,
        "detail": "elasticsearch",
        "documentation": {}
    },
    {
        "label": "Elasticsearch",
        "importPath": "elasticsearch",
        "description": "elasticsearch",
        "isExtraImport": true,
        "detail": "elasticsearch",
        "documentation": {}
    },
    {
        "label": "Elasticsearch",
        "importPath": "elasticsearch",
        "description": "elasticsearch",
        "isExtraImport": true,
        "detail": "elasticsearch",
        "documentation": {}
    },
    {
        "label": "Elasticsearch",
        "importPath": "elasticsearch",
        "description": "elasticsearch",
        "isExtraImport": true,
        "detail": "elasticsearch",
        "documentation": {}
    },
    {
        "label": "helpers",
        "importPath": "elasticsearch",
        "description": "elasticsearch",
        "isExtraImport": true,
        "detail": "elasticsearch",
        "documentation": {}
    },
    {
        "label": "Elasticsearch",
        "importPath": "elasticsearch",
        "description": "elasticsearch",
        "isExtraImport": true,
        "detail": "elasticsearch",
        "documentation": {}
    },
    {
        "label": "Elasticsearch",
        "importPath": "elasticsearch",
        "description": "elasticsearch",
        "isExtraImport": true,
        "detail": "elasticsearch",
        "documentation": {}
    },
    {
        "label": "es_cloud_util,gemini_api_util",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "es_cloud_util.gemini_api_util",
        "description": "es_cloud_util.gemini_api_util",
        "detail": "es_cloud_util.gemini_api_util",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "es_cloud_util,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "es_cloud_util.",
        "description": "es_cloud_util.",
        "detail": "es_cloud_util.",
        "documentation": {}
    },
    {
        "label": "gen_md5",
        "importPath": "common_util",
        "description": "common_util",
        "isExtraImport": true,
        "detail": "common_util",
        "documentation": {}
    },
    {
        "label": "genai",
        "importPath": "google",
        "description": "google",
        "isExtraImport": true,
        "detail": "google",
        "documentation": {}
    },
    {
        "label": "types",
        "importPath": "google.genai",
        "description": "google.genai",
        "isExtraImport": true,
        "detail": "google.genai",
        "documentation": {}
    },
    {
        "label": "os,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.",
        "description": "os.",
        "detail": "os.",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "SentenceTransformer",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "PCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "gen_md5",
        "kind": 2,
        "importPath": "common_util",
        "description": "common_util",
        "peekOfCode": "def gen_md5(text):\n    hash_value = hashlib.md5(text.encode('utf-8')).hexdigest()\n    return hash_value",
        "detail": "common_util",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "create_vector",
        "description": "create_vector",
        "peekOfCode": "response = requests.post(\"https://api.gemini.ai/v1/encode\", json={\"text\": text})\nvector = response.json()[\"vector\"]\n# 连接到 Elasticsearch\nes = Elasticsearch(\n    [\"https://127.0.0.1:9200\"],\n    http_auth=(\"elastic\", \"AVz2_EK*zDFKJnnem3fi\"),\n    ca_certs=\"D:/tools/elasticsearch-9.0.3/config/certs/http_ca.crt\",\n)\n# 存储向量到 Elasticsearch\nes.index(index=\"test-index2\", body={\"vector\": vector})",
        "detail": "create_vector",
        "documentation": {}
    },
    {
        "label": "vector",
        "kind": 5,
        "importPath": "create_vector",
        "description": "create_vector",
        "peekOfCode": "vector = response.json()[\"vector\"]\n# 连接到 Elasticsearch\nes = Elasticsearch(\n    [\"https://127.0.0.1:9200\"],\n    http_auth=(\"elastic\", \"AVz2_EK*zDFKJnnem3fi\"),\n    ca_certs=\"D:/tools/elasticsearch-9.0.3/config/certs/http_ca.crt\",\n)\n# 存储向量到 Elasticsearch\nes.index(index=\"test-index2\", body={\"vector\": vector})",
        "detail": "create_vector",
        "documentation": {}
    },
    {
        "label": "es",
        "kind": 5,
        "importPath": "create_vector",
        "description": "create_vector",
        "peekOfCode": "es = Elasticsearch(\n    [\"https://127.0.0.1:9200\"],\n    http_auth=(\"elastic\", \"AVz2_EK*zDFKJnnem3fi\"),\n    ca_certs=\"D:/tools/elasticsearch-9.0.3/config/certs/http_ca.crt\",\n)\n# 存储向量到 Elasticsearch\nes.index(index=\"test-index2\", body={\"vector\": vector})",
        "detail": "create_vector",
        "documentation": {}
    },
    {
        "label": "update_index_",
        "kind": 2,
        "importPath": "es_cloud_demo2_file_gemini",
        "description": "es_cloud_demo2_file_gemini",
        "peekOfCode": "def update_index_():\n    # 批量索引文件夹中的文件\n    folder_path = \"./doc\"  # 替换为你的文件目录\n    for filename in os.listdir(folder_path):\n        file_path = os.path.join(folder_path, filename)\n        if filename.lower().endswith((\"t.txt\")):\n            es_cloud_util.index_file_chunk_overlap(client, index_name, file_path, dims)\nif __name__ == \"__main__\":\n    update_index_()\n    query_kw = \"appearance\"",
        "detail": "es_cloud_demo2_file_gemini",
        "documentation": {}
    },
    {
        "label": "dims",
        "kind": 5,
        "importPath": "es_cloud_demo2_file_gemini",
        "description": "es_cloud_demo2_file_gemini",
        "peekOfCode": "dims = 768\nclient = Elasticsearch(\n    \"https://my-elasticsearch-project-a6634e.es.us-east-1.aws.elastic.cloud:443\",\n    api_key=\"V1BWMEZwZ0I5UE5nM2tDY3pXS0o6cUxkV1ZMYVlxUEZiMEpaZ3N3em9UQQ==\",\n)\nindex_name = \"index_file_chunk_overlap\"\ndef update_index_():\n    # 批量索引文件夹中的文件\n    folder_path = \"./doc\"  # 替换为你的文件目录\n    for filename in os.listdir(folder_path):",
        "detail": "es_cloud_demo2_file_gemini",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "es_cloud_demo2_file_gemini",
        "description": "es_cloud_demo2_file_gemini",
        "peekOfCode": "client = Elasticsearch(\n    \"https://my-elasticsearch-project-a6634e.es.us-east-1.aws.elastic.cloud:443\",\n    api_key=\"V1BWMEZwZ0I5UE5nM2tDY3pXS0o6cUxkV1ZMYVlxUEZiMEpaZ3N3em9UQQ==\",\n)\nindex_name = \"index_file_chunk_overlap\"\ndef update_index_():\n    # 批量索引文件夹中的文件\n    folder_path = \"./doc\"  # 替换为你的文件目录\n    for filename in os.listdir(folder_path):\n        file_path = os.path.join(folder_path, filename)",
        "detail": "es_cloud_demo2_file_gemini",
        "documentation": {}
    },
    {
        "label": "index_name",
        "kind": 5,
        "importPath": "es_cloud_demo2_file_gemini",
        "description": "es_cloud_demo2_file_gemini",
        "peekOfCode": "index_name = \"index_file_chunk_overlap\"\ndef update_index_():\n    # 批量索引文件夹中的文件\n    folder_path = \"./doc\"  # 替换为你的文件目录\n    for filename in os.listdir(folder_path):\n        file_path = os.path.join(folder_path, filename)\n        if filename.lower().endswith((\"t.txt\")):\n            es_cloud_util.index_file_chunk_overlap(client, index_name, file_path, dims)\nif __name__ == \"__main__\":\n    update_index_()",
        "detail": "es_cloud_demo2_file_gemini",
        "documentation": {}
    },
    {
        "label": "update_index_",
        "kind": 2,
        "importPath": "es_cloud_demo2_file_sentence_transformers",
        "description": "es_cloud_demo2_file_sentence_transformers",
        "peekOfCode": "def update_index_():\n    # 批量索引文件夹中的文件\n    folder_path = \"./doc\"  # 替换为你的文件目录\n    for filename in os.listdir(folder_path):\n        file_path = os.path.join(folder_path, filename)\n        if filename.lower().endswith((\"t.txt\")):\n            # es_cloud_util.index_file_chunk_overlap_sentence_transformers(client, index_name, file_path, dims)\n            es_cloud_util.index_file_chunk_overlap_sentence_transformers(\n                client, index_name, file_path\n            )",
        "detail": "es_cloud_demo2_file_sentence_transformers",
        "documentation": {}
    },
    {
        "label": "query",
        "kind": 2,
        "importPath": "es_cloud_demo2_file_sentence_transformers",
        "description": "es_cloud_demo2_file_sentence_transformers",
        "peekOfCode": "def query(query_kw):\n    query_embedding = sentence_transformers_util.get_embedings([query_kw])[0]\n    es_cloud_util.query(client, index_name, query_embedding)\nif __name__ == \"__main__\":\n    # update_index_()\n    # query_kw = \"The ship was overwhelmed\"\n    query_kw = \"overwhelmed boat\"    \n    query(query_kw)\n    # es_cloud_util.get_property_list(client, index_name)",
        "detail": "es_cloud_demo2_file_sentence_transformers",
        "documentation": {}
    },
    {
        "label": "dims",
        "kind": 5,
        "importPath": "es_cloud_demo2_file_sentence_transformers",
        "description": "es_cloud_demo2_file_sentence_transformers",
        "peekOfCode": "dims = 768\nclient = Elasticsearch(\n    \"https://my-elasticsearch-project-a6634e.es.us-east-1.aws.elastic.cloud:443\",\n    api_key=\"V1BWMEZwZ0I5UE5nM2tDY3pXS0o6cUxkV1ZMYVlxUEZiMEpaZ3N3em9UQQ==\",\n)\nindex_name = \"index_file_chunk_overlap_sentence_transformers\"\ndef update_index_():\n    # 批量索引文件夹中的文件\n    folder_path = \"./doc\"  # 替换为你的文件目录\n    for filename in os.listdir(folder_path):",
        "detail": "es_cloud_demo2_file_sentence_transformers",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "es_cloud_demo2_file_sentence_transformers",
        "description": "es_cloud_demo2_file_sentence_transformers",
        "peekOfCode": "client = Elasticsearch(\n    \"https://my-elasticsearch-project-a6634e.es.us-east-1.aws.elastic.cloud:443\",\n    api_key=\"V1BWMEZwZ0I5UE5nM2tDY3pXS0o6cUxkV1ZMYVlxUEZiMEpaZ3N3em9UQQ==\",\n)\nindex_name = \"index_file_chunk_overlap_sentence_transformers\"\ndef update_index_():\n    # 批量索引文件夹中的文件\n    folder_path = \"./doc\"  # 替换为你的文件目录\n    for filename in os.listdir(folder_path):\n        file_path = os.path.join(folder_path, filename)",
        "detail": "es_cloud_demo2_file_sentence_transformers",
        "documentation": {}
    },
    {
        "label": "index_name",
        "kind": 5,
        "importPath": "es_cloud_demo2_file_sentence_transformers",
        "description": "es_cloud_demo2_file_sentence_transformers",
        "peekOfCode": "index_name = \"index_file_chunk_overlap_sentence_transformers\"\ndef update_index_():\n    # 批量索引文件夹中的文件\n    folder_path = \"./doc\"  # 替换为你的文件目录\n    for filename in os.listdir(folder_path):\n        file_path = os.path.join(folder_path, filename)\n        if filename.lower().endswith((\"t.txt\")):\n            # es_cloud_util.index_file_chunk_overlap_sentence_transformers(client, index_name, file_path, dims)\n            es_cloud_util.index_file_chunk_overlap_sentence_transformers(\n                client, index_name, file_path",
        "detail": "es_cloud_demo2_file_sentence_transformers",
        "documentation": {}
    },
    {
        "label": "update_index_",
        "kind": 2,
        "importPath": "es_cloud_demo2_file_sentence_transformers_dims_32",
        "description": "es_cloud_demo2_file_sentence_transformers_dims_32",
        "peekOfCode": "def update_index_():\n    # 批量索引文件夹中的文件\n    folder_path = \"./doc\"  # 替换为你的文件目录\n    for filename in os.listdir(folder_path):\n        file_path = os.path.join(folder_path, filename)\n        if filename.lower().endswith((\"t.txt\")):\n            es_cloud_util.index_file_chunk_overlap_sentence_transformers(\n                client, index_name, file_path, dims\n            )\ndef query(query_kw):",
        "detail": "es_cloud_demo2_file_sentence_transformers_dims_32",
        "documentation": {}
    },
    {
        "label": "query",
        "kind": 2,
        "importPath": "es_cloud_demo2_file_sentence_transformers_dims_32",
        "description": "es_cloud_demo2_file_sentence_transformers_dims_32",
        "peekOfCode": "def query(query_kw):\n    query_embedding = sentence_transformers_util.get_embedings([query_kw])[0]\n    # Load PCA model\n    with open(\"model/pca_model.pkl\", \"rb\") as f:\n        pca = pickle.load(f)\n        query_embedding = pca.transform([query_embedding]).tolist()[0]\n    es_cloud_util.query(client, index_name, query_embedding)\nif __name__ == \"__main__\":\n    # update_index_()\n    query_kw = \"overwhelmed boat\"",
        "detail": "es_cloud_demo2_file_sentence_transformers_dims_32",
        "documentation": {}
    },
    {
        "label": "dims",
        "kind": 5,
        "importPath": "es_cloud_demo2_file_sentence_transformers_dims_32",
        "description": "es_cloud_demo2_file_sentence_transformers_dims_32",
        "peekOfCode": "dims = 32\nclient = Elasticsearch(\n    \"https://my-elasticsearch-project-a6634e.es.us-east-1.aws.elastic.cloud:443\",\n    api_key=\"V1BWMEZwZ0I5UE5nM2tDY3pXS0o6cUxkV1ZMYVlxUEZiMEpaZ3N3em9UQQ==\",\n)\nindex_name = \"index_file_chunk_overlap_sentence_transformers_dims32\"\ndef update_index_():\n    # 批量索引文件夹中的文件\n    folder_path = \"./doc\"  # 替换为你的文件目录\n    for filename in os.listdir(folder_path):",
        "detail": "es_cloud_demo2_file_sentence_transformers_dims_32",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "es_cloud_demo2_file_sentence_transformers_dims_32",
        "description": "es_cloud_demo2_file_sentence_transformers_dims_32",
        "peekOfCode": "client = Elasticsearch(\n    \"https://my-elasticsearch-project-a6634e.es.us-east-1.aws.elastic.cloud:443\",\n    api_key=\"V1BWMEZwZ0I5UE5nM2tDY3pXS0o6cUxkV1ZMYVlxUEZiMEpaZ3N3em9UQQ==\",\n)\nindex_name = \"index_file_chunk_overlap_sentence_transformers_dims32\"\ndef update_index_():\n    # 批量索引文件夹中的文件\n    folder_path = \"./doc\"  # 替换为你的文件目录\n    for filename in os.listdir(folder_path):\n        file_path = os.path.join(folder_path, filename)",
        "detail": "es_cloud_demo2_file_sentence_transformers_dims_32",
        "documentation": {}
    },
    {
        "label": "index_name",
        "kind": 5,
        "importPath": "es_cloud_demo2_file_sentence_transformers_dims_32",
        "description": "es_cloud_demo2_file_sentence_transformers_dims_32",
        "peekOfCode": "index_name = \"index_file_chunk_overlap_sentence_transformers_dims32\"\ndef update_index_():\n    # 批量索引文件夹中的文件\n    folder_path = \"./doc\"  # 替换为你的文件目录\n    for filename in os.listdir(folder_path):\n        file_path = os.path.join(folder_path, filename)\n        if filename.lower().endswith((\"t.txt\")):\n            es_cloud_util.index_file_chunk_overlap_sentence_transformers(\n                client, index_name, file_path, dims\n            )",
        "detail": "es_cloud_demo2_file_sentence_transformers_dims_32",
        "documentation": {}
    },
    {
        "label": "create_index",
        "kind": 2,
        "importPath": "es_cloud_util",
        "description": "es_cloud_util",
        "peekOfCode": "def create_index(client, index_name, dims):\n    mapping = {\n        \"mappings\": {\n            \"properties\": {\n                \"vector\": {\"type\": \"dense_vector\", \"dims\": dims, \"similarity\": \"cosine\"},\n            }\n        }\n    }\n    result = client.indices.create(index=index_name, body=mapping)\n    print(result)",
        "detail": "es_cloud_util",
        "documentation": {}
    },
    {
        "label": "update_mapping",
        "kind": 2,
        "importPath": "es_cloud_util",
        "description": "es_cloud_util",
        "peekOfCode": "def update_mapping(client, index_name, dims):\n    mapping = {\n        \"mappings\": {\n            \"properties\": {\n                \"vector\": {\"type\": \"dense_vector\", \"dims\": dims, \"similarity\": \"cosine\"},\n            }\n        }\n    }\n    mapping_response = client.indices.put_mapping(index=index_name, body=mapping)\n    print(mapping_response)",
        "detail": "es_cloud_util",
        "documentation": {}
    },
    {
        "label": "update_index",
        "kind": 2,
        "importPath": "es_cloud_util",
        "description": "es_cloud_util",
        "peekOfCode": "def update_index(client, docs, index_name, dims=768,batch_size=32):\n    if not client.indices.exists(index=index_name):\n        create_index(client, index_name, dims)\n    # bulk_response = helpers.bulk(client, docs, index=index_name)\n    for i in range(0, len(docs), batch_size):\n        chunks = docs[i : i + batch_size]\n        print(f\"update_index : Current : {i} to {i + batch_size}\")\n        bulk_response = helpers.bulk(client, chunks, index=index_name)\n        print(bulk_response)\ndef get_property_list(client, index_name, property=\"md5\"):",
        "detail": "es_cloud_util",
        "documentation": {}
    },
    {
        "label": "get_property_list",
        "kind": 2,
        "importPath": "es_cloud_util",
        "description": "es_cloud_util",
        "peekOfCode": "def get_property_list(client, index_name, property=\"md5\"):\n    if not client.indices.exists(index=index_name):\n        return []\n    response = client.search(\n        index=index_name,\n        body={\n            \"query\": {\"exists\": {\"field\": \"md5\"}},\n            \"fields\": [property],\n            \"_source\": False,\n            \"size\": 10000,",
        "detail": "es_cloud_util",
        "documentation": {}
    },
    {
        "label": "index_file_chunk_overlap",
        "kind": 2,
        "importPath": "es_cloud_util",
        "description": "es_cloud_util",
        "peekOfCode": "def index_file_chunk_overlap(client, index_name, file_path, dims, batch_size=100):\n    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n        text = f.read()\n        print(file_path, len(text))\n        chunk_size, overlap = 500, 100\n        # chunk_size, overlap = 50, 10\n        all_chunks = [\n            text[i : i + chunk_size] for i in range(0, len(text), chunk_size - overlap)\n        ]\n        for i in range(0, len(all_chunks), batch_size):",
        "detail": "es_cloud_util",
        "documentation": {}
    },
    {
        "label": "index_file_chunk_overlap_sentence_transformers",
        "kind": 2,
        "importPath": "es_cloud_util",
        "description": "es_cloud_util",
        "peekOfCode": "def index_file_chunk_overlap_sentence_transformers(\n    client, index_name, file_path, dims=0\n):\n    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n        text = f.read()\n        print(file_path, len(text))\n        chunk_size, overlap = 500, 100\n        # chunk_size, overlap = 50, 10\n        chunks = [\n            text[i : i + chunk_size] for i in range(0, len(text), chunk_size - overlap)",
        "detail": "es_cloud_util",
        "documentation": {}
    },
    {
        "label": "query",
        "kind": 2,
        "importPath": "es_cloud_util",
        "description": "es_cloud_util",
        "peekOfCode": "def query(client, index_name, query_embedding):\n    body = {\n        \"size\": 3,\n        \"query\": {\n            \"script_score\": {\n                \"query\": {\"match_all\": {}},\n                \"script\": {\n                    \"source\": \"cosineSimilarity(params.query_vector, 'vector') + 1.0\",\n                    \"params\": {\"query_vector\": query_embedding},\n                },",
        "detail": "es_cloud_util",
        "documentation": {}
    },
    {
        "label": "get_ai_client",
        "kind": 2,
        "importPath": "gemini_api_util",
        "description": "gemini_api_util",
        "peekOfCode": "def get_ai_client():\n    api_key = os.environ.get(\"gemini_api_key2\")\n    client = genai.Client(api_key=api_key)\n    return client\ndef get_embedings(texts, dims, model=\"gemini-embedding-001\", batch_size=100):\n    embeddings = []\n    client = get_ai_client()\n    for i in range(0, len(texts), batch_size):\n        batch = texts[i : i + batch_size]  # 每批最多 100 个\n        try:",
        "detail": "gemini_api_util",
        "documentation": {}
    },
    {
        "label": "get_embedings",
        "kind": 2,
        "importPath": "gemini_api_util",
        "description": "gemini_api_util",
        "peekOfCode": "def get_embedings(texts, dims, model=\"gemini-embedding-001\", batch_size=100):\n    embeddings = []\n    client = get_ai_client()\n    for i in range(0, len(texts), batch_size):\n        batch = texts[i : i + batch_size]  # 每批最多 100 个\n        try:\n            result = client.models.embed_content(\n                model=model,\n                contents=batch,\n                config=types.EmbedContentConfig(output_dimensionality=dims),",
        "detail": "gemini_api_util",
        "documentation": {}
    },
    {
        "label": "index_file",
        "kind": 2,
        "importPath": "localES_create_index",
        "description": "localES_create_index",
        "peekOfCode": "def index_file(file_path, index_name):\n    try:\n        with open(file_path, \"rb\") as f:\n            content = base64.b64encode(f.read()).decode(\"utf-8\")\n        doc = {\n            \"name\": os.path.basename(file_path),\n            \"type\": os.path.splitext(file_path)[1][1:].lower(),\n            \"content\": content\n        }\n        # 索引文件，使用 test1 管道",
        "detail": "localES_create_index",
        "documentation": {}
    },
    {
        "label": "es",
        "kind": 5,
        "importPath": "localES_create_index",
        "description": "localES_create_index",
        "peekOfCode": "es = Elasticsearch(\n    [\"https://127.0.0.1:9200\"],\n    http_auth=(\"elastic\", \"AVz2_EK*zDFKJnnem3fi\"),\n    ca_certs=\"D:/tools/elasticsearch-9.0.3/config/certs/http_ca.crt\",\n)\nindex_name=\"test-index1\"\ndef index_file(file_path, index_name):\n    try:\n        with open(file_path, \"rb\") as f:\n            content = base64.b64encode(f.read()).decode(\"utf-8\")",
        "detail": "localES_create_index",
        "documentation": {}
    },
    {
        "label": "folder_path",
        "kind": 5,
        "importPath": "localES_create_index",
        "description": "localES_create_index",
        "peekOfCode": "folder_path = \"./doc\"  # 替换为你的文件目录\nfor filename in os.listdir(folder_path):\n    file_path = os.path.join(folder_path, filename)\n    if filename.lower().endswith(('.pdf', '.doc', '.docx', '.xls', '.xlsx','txt','ppt')):\n        index_file(file_path,index_name)",
        "detail": "localES_create_index",
        "documentation": {}
    },
    {
        "label": "search",
        "kind": 2,
        "importPath": "search_ui",
        "description": "search_ui",
        "peekOfCode": "def search():\n    query = request.args.get('q', '')\n    body = {\n        \"query\": {\n            \"match\": {\n                \"attachment.content\": query\n            }\n        },\n        \"highlight\": {\n            \"fields\": {",
        "detail": "search_ui",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "search_ui",
        "description": "search_ui",
        "peekOfCode": "app = Flask(__name__)\nes = Elasticsearch([\"http://127.0.0.1:9200\"])\n@app.route('/search', methods=['GET'])\ndef search():\n    query = request.args.get('q', '')\n    body = {\n        \"query\": {\n            \"match\": {\n                \"attachment.content\": query\n            }",
        "detail": "search_ui",
        "documentation": {}
    },
    {
        "label": "es",
        "kind": 5,
        "importPath": "search_ui",
        "description": "search_ui",
        "peekOfCode": "es = Elasticsearch([\"http://127.0.0.1:9200\"])\n@app.route('/search', methods=['GET'])\ndef search():\n    query = request.args.get('q', '')\n    body = {\n        \"query\": {\n            \"match\": {\n                \"attachment.content\": query\n            }\n        },",
        "detail": "search_ui",
        "documentation": {}
    },
    {
        "label": "get_embedings",
        "kind": 2,
        "importPath": "sentence_transformers_util",
        "description": "sentence_transformers_util",
        "peekOfCode": "def get_embedings(\n    texts, dims=0, model_name=\"paraphrase-multilingual-mpnet-base-v2\", batch_size=32\n):\n    model = SentenceTransformer(model_name)\n    result = model.encode(texts, normalize_embeddings=True, batch_size=batch_size)\n    if dims:\n        result = change_dims(result, dims)\n    return result.tolist()\n# def get_one_embeding(text, dims=0, model_name='paraphrase-multilingual-mpnet-base-v2'):\n#     model = SentenceTransformer(model_name)",
        "detail": "sentence_transformers_util",
        "documentation": {}
    },
    {
        "label": "change_dims",
        "kind": 2,
        "importPath": "sentence_transformers_util",
        "description": "sentence_transformers_util",
        "peekOfCode": "def change_dims(embeddings, target_dims):\n    # target_dims = 256\n    pca = PCA(n_components=target_dims)\n    reduced_embeddings = pca.fit_transform(embeddings)\n    # Save PCA model tor translate query embeddings to target_dims\n    with open(\"model/pca_model.pkl\", \"wb\") as f:\n        pickle.dump(pca, f)\n    return reduced_embeddings\nif __name__ == \"__main__\":\n    # get_one_embeding('hello world')",
        "detail": "sentence_transformers_util",
        "documentation": {}
    },
    {
        "label": "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"]",
        "kind": 5,
        "importPath": "sentence_transformers_util",
        "description": "sentence_transformers_util",
        "peekOfCode": "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.decomposition import PCA\nimport numpy as np,pickle\ndef get_embedings(\n    texts, dims=0, model_name=\"paraphrase-multilingual-mpnet-base-v2\", batch_size=32\n):\n    model = SentenceTransformer(model_name)\n    result = model.encode(texts, normalize_embeddings=True, batch_size=batch_size)\n    if dims:",
        "detail": "sentence_transformers_util",
        "documentation": {}
    }
]